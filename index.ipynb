{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Statistics with Functions - Lab\n",
    "\n",
    "## Introduction \n",
    "In this lab you'll dive deep into calculating the measures of central tendency and dispersion introduced in previous lessons. You will code the formulas for these functions in Python which will require you to use the programming skills that you have gained in the other lessons of this section. Let's get started!\n",
    "\n",
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "\n",
    "* Calculate the measures of dispersion for a dataset\n",
    "* Compare the different measures of dispersion\n",
    "* Calculate the measures of central tendency for a dataset\n",
    "* Compare the different measures of central tendency\n",
    "\n",
    "## Dataset\n",
    "\n",
    "For this lab, we'll use the [NHIS dataset](http://people.ucsc.edu/~cdobkin/NHIS%202007%20data.csv), which contains weights, heights, and some other attributes for a number of surveyed individuals. The context of this survey is outside the scope this lab, so we'll just go ahead and load the heights column as a list for us to run some simple statistical experiments. We'll use the `pandas` library to import the data into our Python environment. This process will be covered in detail in a later section. For now, we'll do this part for you to give you a head start.  \n",
    "\n",
    "Run the cell below to import the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a data analys always follow the **CRISP-DM** methodology. This methodology allows you to do the following steps/to follow:\n",
    "\n",
    "**1. Business understanding**\n",
    "* Define the project by providing an overview, objectives and requirements from a business perspective.\n",
    "  \n",
    "**2. Data Understanding**\n",
    "* You will need to collect, describe and explore data\n",
    "  \n",
    "**3. Data preparation**\n",
    "* You will be required to clean and transform the data for further analysis\n",
    "  \n",
    "**4. Exploratory data Analysis (EDA)**\n",
    "* You will be able to explore and perform analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HHX</th>\n",
       "      <th>FMX</th>\n",
       "      <th>FPX</th>\n",
       "      <th>SEX</th>\n",
       "      <th>BMI</th>\n",
       "      <th>SLEEP</th>\n",
       "      <th>educ</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>33.36</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>74</td>\n",
       "      <td>260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26.54</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>70</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>32.13</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>61</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26.62</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>68</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>27.13</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>66</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>99.99</td>\n",
       "      <td>98</td>\n",
       "      <td>12</td>\n",
       "      <td>98</td>\n",
       "      <td>998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99.99</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>99</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   HHX  FMX  FPX  SEX    BMI  SLEEP  educ  height  weight\n",
       "0   16    1    2    1  33.36      8    16      74     260\n",
       "1   20    1    1    1  26.54      7    14      70     185\n",
       "2   69    1    2    2  32.13      7     9      61     170\n",
       "3   87    1    1    1  26.62      8    14      68     175\n",
       "4   88    1    1    2  27.13      8    13      66     168\n",
       "5   99    1    1    2  99.99     98    12      98     998\n",
       "6  101    1    1    1  99.99      6    13      99     172"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('nhis.csv') #if you are loading excel, then it will be pd.excel('nhis.xlsx')\n",
    "#review first 5 raws\n",
    "df.head(7)\n",
    "#height = list(df['height'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['HHX', 'FMX', 'FPX', 'SEX', 'BMI', 'SLEEP', 'educ', 'height', 'weight'], dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HHX</th>\n",
       "      <th>FMX</th>\n",
       "      <th>FPX</th>\n",
       "      <th>SEX</th>\n",
       "      <th>BMI</th>\n",
       "      <th>SLEEP</th>\n",
       "      <th>educ</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4785.000000</td>\n",
       "      <td>4785.000000</td>\n",
       "      <td>4785.000000</td>\n",
       "      <td>4785.000000</td>\n",
       "      <td>4785.000000</td>\n",
       "      <td>4785.000000</td>\n",
       "      <td>4785.000000</td>\n",
       "      <td>4785.000000</td>\n",
       "      <td>4785.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>27009.074190</td>\n",
       "      <td>1.019227</td>\n",
       "      <td>1.358621</td>\n",
       "      <td>1.548589</td>\n",
       "      <td>31.730665</td>\n",
       "      <td>9.506792</td>\n",
       "      <td>14.248903</td>\n",
       "      <td>69.578265</td>\n",
       "      <td>266.235737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>15576.508793</td>\n",
       "      <td>0.188636</td>\n",
       "      <td>0.601803</td>\n",
       "      <td>0.497685</td>\n",
       "      <td>17.658336</td>\n",
       "      <td>14.732155</td>\n",
       "      <td>9.025264</td>\n",
       "      <td>9.367217</td>\n",
       "      <td>262.076677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>16.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.910000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>13404.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>23.630000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>149.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>27527.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>26.970000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>175.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>40192.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>31.510000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>215.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>53955.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>99.990000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>999.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                HHX          FMX          FPX          SEX          BMI  \\\n",
       "count   4785.000000  4785.000000  4785.000000  4785.000000  4785.000000   \n",
       "mean   27009.074190     1.019227     1.358621     1.548589    31.730665   \n",
       "std    15576.508793     0.188636     0.601803     0.497685    17.658336   \n",
       "min       16.000000     1.000000     1.000000     1.000000    12.910000   \n",
       "25%    13404.000000     1.000000     1.000000     1.000000    23.630000   \n",
       "50%    27527.000000     1.000000     1.000000     2.000000    26.970000   \n",
       "75%    40192.000000     1.000000     2.000000     2.000000    31.510000   \n",
       "max    53955.000000     6.000000     8.000000     2.000000    99.990000   \n",
       "\n",
       "             SLEEP         educ       height       weight  \n",
       "count  4785.000000  4785.000000  4785.000000  4785.000000  \n",
       "mean      9.506792    14.248903    69.578265   266.235737  \n",
       "std      14.732155     9.025264     9.367217   262.076677  \n",
       "min       3.000000     0.000000    59.000000   100.000000  \n",
       "25%       6.000000    12.000000    64.000000   149.000000  \n",
       "50%       7.000000    13.000000    67.000000   175.000000  \n",
       "75%       8.000000    16.000000    71.000000   215.000000  \n",
       "max      99.000000    99.000000    99.000000   999.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()# will give you summary statistics of every numerical column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Next I shall create a variable name:height and assaign the values of the 'height' on it by using the ```list()``` function as shown in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the variable height and assaign the height values to it\n",
    "df['height']\n",
    "list(df['height'])\n",
    "#type(list(df['height']))\n",
    "height = list(df['height'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4785"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the number of values in the height column\n",
    "len(height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[74,\n",
       " 70,\n",
       " 61,\n",
       " 68,\n",
       " 66,\n",
       " 98,\n",
       " 99,\n",
       " 70,\n",
       " 65,\n",
       " 64,\n",
       " 65,\n",
       " 66,\n",
       " 99,\n",
       " 61,\n",
       " 61,\n",
       " 65,\n",
       " 68,\n",
       " 64,\n",
       " 64,\n",
       " 66,\n",
       " 67,\n",
       " 72,\n",
       " 61,\n",
       " 96,\n",
       " 65,\n",
       " 61,\n",
       " 66,\n",
       " 64,\n",
       " 72,\n",
       " 64,\n",
       " 64,\n",
       " 71,\n",
       " 64,\n",
       " 72,\n",
       " 70,\n",
       " 66,\n",
       " 74,\n",
       " 76,\n",
       " 68,\n",
       " 66,\n",
       " 66,\n",
       " 69,\n",
       " 61,\n",
       " 64,\n",
       " 66,\n",
       " 69,\n",
       " 66,\n",
       " 71,\n",
       " 71,\n",
       " 63,\n",
       " 68,\n",
       " 75,\n",
       " 64,\n",
       " 62,\n",
       " 96,\n",
       " 65,\n",
       " 64,\n",
       " 60,\n",
       " 62,\n",
       " 61,\n",
       " 63,\n",
       " 72,\n",
       " 72,\n",
       " 63,\n",
       " 67,\n",
       " 65,\n",
       " 64,\n",
       " 61,\n",
       " 66,\n",
       " 65,\n",
       " 68,\n",
       " 64,\n",
       " 71,\n",
       " 65,\n",
       " 63,\n",
       " 64,\n",
       " 72,\n",
       " 65,\n",
       " 71,\n",
       " 72,\n",
       " 64,\n",
       " 65,\n",
       " 72,\n",
       " 69,\n",
       " 66,\n",
       " 64,\n",
       " 96,\n",
       " 66,\n",
       " 96,\n",
       " 69,\n",
       " 67,\n",
       " 66,\n",
       " 59,\n",
       " 60,\n",
       " 62,\n",
       " 70,\n",
       " 61,\n",
       " 66,\n",
       " 97,\n",
       " 96,\n",
       " 62,\n",
       " 67,\n",
       " 59,\n",
       " 70,\n",
       " 66,\n",
       " 60,\n",
       " 68,\n",
       " 67,\n",
       " 65,\n",
       " 71,\n",
       " 63,\n",
       " 63,\n",
       " 71,\n",
       " 67,\n",
       " 65,\n",
       " 66,\n",
       " 66,\n",
       " 70,\n",
       " 68,\n",
       " 64,\n",
       " 62,\n",
       " 60,\n",
       " 73,\n",
       " 68,\n",
       " 62,\n",
       " 61,\n",
       " 65,\n",
       " 66,\n",
       " 64,\n",
       " 60,\n",
       " 59,\n",
       " 61,\n",
       " 63,\n",
       " 98,\n",
       " 60,\n",
       " 62,\n",
       " 63,\n",
       " 65,\n",
       " 68,\n",
       " 72,\n",
       " 67,\n",
       " 72,\n",
       " 66,\n",
       " 61,\n",
       " 96,\n",
       " 64,\n",
       " 96,\n",
       " 64,\n",
       " 71,\n",
       " 72,\n",
       " 65,\n",
       " 67,\n",
       " 63,\n",
       " 68,\n",
       " 65,\n",
       " 96,\n",
       " 71,\n",
       " 62,\n",
       " 69,\n",
       " 64,\n",
       " 66,\n",
       " 63,\n",
       " 67,\n",
       " 69,\n",
       " 66,\n",
       " 61,\n",
       " 68,\n",
       " 60,\n",
       " 72,\n",
       " 70,\n",
       " 65,\n",
       " 67,\n",
       " 63,\n",
       " 69,\n",
       " 64,\n",
       " 96,\n",
       " 67,\n",
       " 74,\n",
       " 62,\n",
       " 69,\n",
       " 60,\n",
       " 73,\n",
       " 96,\n",
       " 67,\n",
       " 98,\n",
       " 62,\n",
       " 69,\n",
       " 64,\n",
       " 68,\n",
       " 72,\n",
       " 74,\n",
       " 72,\n",
       " 64,\n",
       " 66,\n",
       " 68,\n",
       " 65,\n",
       " 61,\n",
       " 69,\n",
       " 71,\n",
       " 66,\n",
       " 65,\n",
       " 68,\n",
       " 65,\n",
       " 68,\n",
       " 68,\n",
       " 72,\n",
       " 62,\n",
       " 60,\n",
       " 72,\n",
       " 71,\n",
       " 65,\n",
       " 62,\n",
       " 74,\n",
       " 71,\n",
       " 67,\n",
       " 67,\n",
       " 66,\n",
       " 69,\n",
       " 67,\n",
       " 66,\n",
       " 96,\n",
       " 72,\n",
       " 65,\n",
       " 61,\n",
       " 68,\n",
       " 98,\n",
       " 68,\n",
       " 70,\n",
       " 68,\n",
       " 70,\n",
       " 71,\n",
       " 65,\n",
       " 69,\n",
       " 98,\n",
       " 68,\n",
       " 70,\n",
       " 67,\n",
       " 60,\n",
       " 65,\n",
       " 63,\n",
       " 74,\n",
       " 67,\n",
       " 67,\n",
       " 63,\n",
       " 67,\n",
       " 69,\n",
       " 96,\n",
       " 67,\n",
       " 65,\n",
       " 64,\n",
       " 72,\n",
       " 72,\n",
       " 67,\n",
       " 63,\n",
       " 64,\n",
       " 65,\n",
       " 68,\n",
       " 65,\n",
       " 64,\n",
       " 99,\n",
       " 64,\n",
       " 61,\n",
       " 60,\n",
       " 63,\n",
       " 69,\n",
       " 96,\n",
       " 96,\n",
       " 64,\n",
       " 70,\n",
       " 73,\n",
       " 65,\n",
       " 68,\n",
       " 98,\n",
       " 70,\n",
       " 60,\n",
       " 67,\n",
       " 70,\n",
       " 66,\n",
       " 67,\n",
       " 66,\n",
       " 72,\n",
       " 73,\n",
       " 69,\n",
       " 67,\n",
       " 63,\n",
       " 70,\n",
       " 69,\n",
       " 63,\n",
       " 60,\n",
       " 70,\n",
       " 66,\n",
       " 70,\n",
       " 67,\n",
       " 66,\n",
       " 60,\n",
       " 96,\n",
       " 69,\n",
       " 62,\n",
       " 67,\n",
       " 64,\n",
       " 72,\n",
       " 70,\n",
       " 67,\n",
       " 68,\n",
       " 72,\n",
       " 61,\n",
       " 65,\n",
       " 69,\n",
       " 65,\n",
       " 66,\n",
       " 69,\n",
       " 66,\n",
       " 63,\n",
       " 64,\n",
       " 62,\n",
       " 72,\n",
       " 67,\n",
       " 72,\n",
       " 62,\n",
       " 67,\n",
       " 64,\n",
       " 67,\n",
       " 62,\n",
       " 64,\n",
       " 69,\n",
       " 64,\n",
       " 71,\n",
       " 60,\n",
       " 70,\n",
       " 69,\n",
       " 66,\n",
       " 69,\n",
       " 96,\n",
       " 96,\n",
       " 66,\n",
       " 70,\n",
       " 75,\n",
       " 69,\n",
       " 73,\n",
       " 71,\n",
       " 69,\n",
       " 66,\n",
       " 67,\n",
       " 72,\n",
       " 62,\n",
       " 96,\n",
       " 64,\n",
       " 65,\n",
       " 73,\n",
       " 70,\n",
       " 96,\n",
       " 70,\n",
       " 64,\n",
       " 73,\n",
       " 60,\n",
       " 96,\n",
       " 70,\n",
       " 70,\n",
       " 71,\n",
       " 73,\n",
       " 63,\n",
       " 68,\n",
       " 63,\n",
       " 67,\n",
       " 70,\n",
       " 64,\n",
       " 68,\n",
       " 62,\n",
       " 71,\n",
       " 72,\n",
       " 64,\n",
       " 69,\n",
       " 67,\n",
       " 69,\n",
       " 69,\n",
       " 70,\n",
       " 98,\n",
       " 62,\n",
       " 76,\n",
       " 96,\n",
       " 63,\n",
       " 65,\n",
       " 70,\n",
       " 75,\n",
       " 65,\n",
       " 70,\n",
       " 66,\n",
       " 68,\n",
       " 98,\n",
       " 65,\n",
       " 68,\n",
       " 64,\n",
       " 62,\n",
       " 62,\n",
       " 66,\n",
       " 64,\n",
       " 73,\n",
       " 66,\n",
       " 65,\n",
       " 64,\n",
       " 67,\n",
       " 67,\n",
       " 65,\n",
       " 99,\n",
       " 66,\n",
       " 67,\n",
       " 70,\n",
       " 72,\n",
       " 62,\n",
       " 67,\n",
       " 72,\n",
       " 68,\n",
       " 63,\n",
       " 70,\n",
       " 60,\n",
       " 65,\n",
       " 61,\n",
       " 65,\n",
       " 99,\n",
       " 65,\n",
       " 74,\n",
       " 72,\n",
       " 98,\n",
       " 70,\n",
       " 70,\n",
       " 65,\n",
       " 65,\n",
       " 68,\n",
       " 96,\n",
       " 66,\n",
       " 66,\n",
       " 73,\n",
       " 70,\n",
       " 74,\n",
       " 68,\n",
       " 67,\n",
       " 65,\n",
       " 96,\n",
       " 71,\n",
       " 68,\n",
       " 69,\n",
       " 68,\n",
       " 72,\n",
       " 63,\n",
       " 62,\n",
       " 66,\n",
       " 63,\n",
       " 96,\n",
       " 64,\n",
       " 70,\n",
       " 65,\n",
       " 67,\n",
       " 62,\n",
       " 73,\n",
       " 62,\n",
       " 66,\n",
       " 64,\n",
       " 64,\n",
       " 65,\n",
       " 96,\n",
       " 62,\n",
       " 68,\n",
       " 73,\n",
       " 63,\n",
       " 63,\n",
       " 66,\n",
       " 63,\n",
       " 64,\n",
       " 65,\n",
       " 73,\n",
       " 65,\n",
       " 66,\n",
       " 62,\n",
       " 72,\n",
       " 65,\n",
       " 61,\n",
       " 64,\n",
       " 67,\n",
       " 96,\n",
       " 62,\n",
       " 69,\n",
       " 75,\n",
       " 62,\n",
       " 65,\n",
       " 66,\n",
       " 63,\n",
       " 67,\n",
       " 66,\n",
       " 70,\n",
       " 61,\n",
       " 63,\n",
       " 62,\n",
       " 63,\n",
       " 65,\n",
       " 63,\n",
       " 69,\n",
       " 68,\n",
       " 64,\n",
       " 65,\n",
       " 63,\n",
       " 64,\n",
       " 72,\n",
       " 64,\n",
       " 63,\n",
       " 71,\n",
       " 62,\n",
       " 96,\n",
       " 69,\n",
       " 72,\n",
       " 68,\n",
       " 99,\n",
       " 67,\n",
       " 73,\n",
       " 73,\n",
       " 64,\n",
       " 66,\n",
       " 63,\n",
       " 66,\n",
       " 69,\n",
       " 71,\n",
       " 63,\n",
       " 74,\n",
       " 66,\n",
       " 96,\n",
       " 66,\n",
       " 66,\n",
       " 66,\n",
       " 62,\n",
       " 63,\n",
       " 64,\n",
       " 62,\n",
       " 96,\n",
       " 64,\n",
       " 71,\n",
       " 63,\n",
       " 74,\n",
       " 60,\n",
       " 73,\n",
       " 64,\n",
       " 66,\n",
       " 71,\n",
       " 65,\n",
       " 71,\n",
       " 66,\n",
       " 64,\n",
       " 71,\n",
       " 98,\n",
       " 60,\n",
       " 71,\n",
       " 99,\n",
       " 71,\n",
       " 72,\n",
       " 71,\n",
       " 72,\n",
       " 68,\n",
       " 60,\n",
       " 65,\n",
       " 64,\n",
       " 73,\n",
       " 70,\n",
       " 71,\n",
       " 72,\n",
       " 64,\n",
       " 76,\n",
       " 73,\n",
       " 60,\n",
       " 63,\n",
       " 63,\n",
       " 96,\n",
       " 63,\n",
       " 96,\n",
       " 60,\n",
       " 67,\n",
       " 71,\n",
       " 72,\n",
       " 64,\n",
       " 66,\n",
       " 67,\n",
       " 72,\n",
       " 65,\n",
       " 73,\n",
       " 65,\n",
       " 64,\n",
       " 66,\n",
       " 66,\n",
       " 71,\n",
       " 72,\n",
       " 62,\n",
       " 64,\n",
       " 70,\n",
       " 97,\n",
       " 69,\n",
       " 73,\n",
       " 74,\n",
       " 59,\n",
       " 67,\n",
       " 96,\n",
       " 67,\n",
       " 67,\n",
       " 68,\n",
       " 68,\n",
       " 68,\n",
       " 66,\n",
       " 64,\n",
       " 62,\n",
       " 65,\n",
       " 73,\n",
       " 96,\n",
       " 67,\n",
       " 72,\n",
       " 68,\n",
       " 66,\n",
       " 69,\n",
       " 63,\n",
       " 73,\n",
       " 62,\n",
       " 76,\n",
       " 64,\n",
       " 69,\n",
       " 73,\n",
       " 69,\n",
       " 68,\n",
       " 73,\n",
       " 68,\n",
       " 71,\n",
       " 65,\n",
       " 60,\n",
       " 68,\n",
       " 96,\n",
       " 66,\n",
       " 72,\n",
       " 74,\n",
       " 63,\n",
       " 64,\n",
       " 71,\n",
       " 96,\n",
       " 75,\n",
       " 96,\n",
       " 70,\n",
       " 68,\n",
       " 70,\n",
       " 65,\n",
       " 69,\n",
       " 62,\n",
       " 62,\n",
       " 76,\n",
       " 64,\n",
       " 62,\n",
       " 67,\n",
       " 74,\n",
       " 96,\n",
       " 70,\n",
       " 66,\n",
       " 98,\n",
       " 74,\n",
       " 62,\n",
       " 67,\n",
       " 74,\n",
       " 63,\n",
       " 96,\n",
       " 96,\n",
       " 69,\n",
       " 64,\n",
       " 69,\n",
       " 76,\n",
       " 64,\n",
       " 74,\n",
       " 72,\n",
       " 69,\n",
       " 68,\n",
       " 65,\n",
       " 60,\n",
       " 64,\n",
       " 62,\n",
       " 65,\n",
       " 67,\n",
       " 65,\n",
       " 62,\n",
       " 73,\n",
       " 73,\n",
       " 69,\n",
       " 66,\n",
       " 69,\n",
       " 64,\n",
       " 65,\n",
       " 70,\n",
       " 69,\n",
       " 63,\n",
       " 64,\n",
       " 97,\n",
       " 64,\n",
       " 70,\n",
       " 96,\n",
       " 67,\n",
       " 69,\n",
       " 69,\n",
       " 68,\n",
       " 68,\n",
       " 65,\n",
       " 71,\n",
       " 66,\n",
       " 65,\n",
       " 97,\n",
       " 62,\n",
       " 69,\n",
       " 75,\n",
       " 61,\n",
       " 98,\n",
       " 71,\n",
       " 70,\n",
       " 65,\n",
       " 69,\n",
       " 66,\n",
       " 67,\n",
       " 70,\n",
       " 73,\n",
       " 69,\n",
       " 74,\n",
       " 70,\n",
       " 64,\n",
       " 72,\n",
       " 97,\n",
       " 62,\n",
       " 67,\n",
       " 99,\n",
       " 70,\n",
       " 65,\n",
       " 63,\n",
       " 67,\n",
       " 67,\n",
       " 96,\n",
       " 72,\n",
       " 59,\n",
       " 72,\n",
       " 63,\n",
       " 59,\n",
       " 65,\n",
       " 72,\n",
       " 69,\n",
       " 72,\n",
       " 60,\n",
       " 66,\n",
       " 70,\n",
       " 60,\n",
       " 70,\n",
       " 64,\n",
       " 68,\n",
       " 71,\n",
       " 68,\n",
       " 64,\n",
       " 61,\n",
       " 70,\n",
       " 65,\n",
       " 61,\n",
       " 63,\n",
       " 68,\n",
       " 66,\n",
       " 76,\n",
       " 96,\n",
       " 68,\n",
       " 66,\n",
       " 70,\n",
       " 66,\n",
       " 64,\n",
       " 68,\n",
       " 65,\n",
       " 73,\n",
       " 66,\n",
       " 69,\n",
       " 63,\n",
       " 65,\n",
       " 71,\n",
       " 70,\n",
       " 70,\n",
       " 72,\n",
       " 65,\n",
       " 64,\n",
       " 62,\n",
       " 64,\n",
       " 96,\n",
       " 60,\n",
       " 68,\n",
       " 66,\n",
       " 66,\n",
       " 72,\n",
       " 67,\n",
       " 67,\n",
       " 69,\n",
       " 66,\n",
       " 96,\n",
       " 61,\n",
       " 68,\n",
       " 63,\n",
       " 62,\n",
       " 66,\n",
       " 62,\n",
       " 64,\n",
       " 66,\n",
       " 68,\n",
       " 65,\n",
       " 74,\n",
       " 70,\n",
       " 69,\n",
       " 67,\n",
       " 60,\n",
       " 96,\n",
       " 68,\n",
       " 66,\n",
       " 64,\n",
       " 69,\n",
       " 64,\n",
       " 63,\n",
       " 72,\n",
       " 64,\n",
       " 65,\n",
       " 68,\n",
       " 70,\n",
       " 67,\n",
       " 69,\n",
       " 66,\n",
       " 61,\n",
       " 66,\n",
       " 71,\n",
       " 96,\n",
       " 96,\n",
       " 66,\n",
       " 70,\n",
       " 63,\n",
       " 76,\n",
       " 64,\n",
       " 66,\n",
       " 70,\n",
       " 71,\n",
       " 71,\n",
       " 66,\n",
       " 64,\n",
       " 66,\n",
       " 96,\n",
       " 75,\n",
       " 67,\n",
       " 72,\n",
       " 98,\n",
       " 96,\n",
       " 71,\n",
       " 66,\n",
       " 67,\n",
       " 72,\n",
       " 74,\n",
       " 71,\n",
       " 64,\n",
       " 63,\n",
       " 65,\n",
       " 60,\n",
       " 66,\n",
       " 72,\n",
       " 62,\n",
       " 69,\n",
       " 70,\n",
       " 65,\n",
       " 70,\n",
       " 72,\n",
       " 63,\n",
       " 65,\n",
       " 75,\n",
       " 67,\n",
       " 62,\n",
       " 69,\n",
       " 67,\n",
       " 75,\n",
       " 66,\n",
       " 68,\n",
       " 67,\n",
       " 72,\n",
       " 67,\n",
       " 61,\n",
       " 60,\n",
       " 65,\n",
       " 66,\n",
       " 61,\n",
       " 65,\n",
       " 62,\n",
       " 72,\n",
       " 67,\n",
       " 62,\n",
       " 98,\n",
       " 71,\n",
       " 96,\n",
       " 66,\n",
       " 67,\n",
       " 65,\n",
       " 63,\n",
       " 70,\n",
       " 70,\n",
       " 71,\n",
       " 96,\n",
       " 63,\n",
       " 68,\n",
       " 66,\n",
       " 65,\n",
       " 63,\n",
       " 61,\n",
       " 62,\n",
       " 68,\n",
       " 63,\n",
       " 66,\n",
       " 67,\n",
       " 62,\n",
       " 63,\n",
       " 67,\n",
       " 68,\n",
       " 64,\n",
       " 98,\n",
       " 69,\n",
       " 66,\n",
       " 61,\n",
       " 63,\n",
       " 69,\n",
       " 64,\n",
       " 64,\n",
       " 72,\n",
       " 66,\n",
       " 60,\n",
       " 65,\n",
       " 74,\n",
       " 68,\n",
       " 71,\n",
       " 62,\n",
       " 65,\n",
       " 63,\n",
       " 65,\n",
       " 96,\n",
       " 65,\n",
       " 66,\n",
       " 72,\n",
       " 67,\n",
       " 63,\n",
       " 66,\n",
       " 69,\n",
       " 65,\n",
       " 65,\n",
       " 71,\n",
       " 73,\n",
       " 72,\n",
       " 68,\n",
       " 62,\n",
       " 64,\n",
       " 66,\n",
       " 63,\n",
       " 69,\n",
       " 63,\n",
       " 67,\n",
       " 59,\n",
       " 71,\n",
       " 64,\n",
       " 98,\n",
       " 71,\n",
       " 64,\n",
       " 65,\n",
       " 67,\n",
       " 65,\n",
       " 65,\n",
       " 71,\n",
       " 71,\n",
       " 59,\n",
       " 67,\n",
       " 68,\n",
       " 71,\n",
       " 98,\n",
       " 64,\n",
       " 67,\n",
       " 72,\n",
       " 76,\n",
       " 96,\n",
       " 98,\n",
       " 72,\n",
       " 68,\n",
       " 64,\n",
       " 69,\n",
       " 64,\n",
       " 62,\n",
       " 98,\n",
       " 71,\n",
       " 72,\n",
       " 62,\n",
       " 98,\n",
       " 71,\n",
       " 69,\n",
       " 65,\n",
       " 64,\n",
       " 60,\n",
       " 72,\n",
       " 96,\n",
       " 64,\n",
       " 72,\n",
       " 65,\n",
       " 70,\n",
       " 62,\n",
       " 62,\n",
       " 66,\n",
       " 72,\n",
       " ...]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare the height variable of the height column\n",
    "height\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are only interested in the height column, so we saved it as a list in the variable `height` in the cell above. \n",
    "\n",
    "In the cells below:\n",
    "\n",
    "* Display the number of items in `height`\n",
    "* Slice and display the first 10 items from `height`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4785"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace None with appropriate code\n",
    "num_records = len(height)\n",
    "\n",
    "num_records # 4785"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[74, 70, 61, 68, 66, 98, 99, 70, 65, 64]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace None with appropriate code\n",
    "first_10 = height[:10]\n",
    "\n",
    "first_10 # [74, 70, 61, 68, 66, 98, 99, 70, 65, 64]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, around 4800 records of height. That's great. Next, we'll try plotting some basic **_histograms_** for these records. \n",
    "\n",
    "## Plotting Histograms\n",
    "\n",
    "We'll begin by importing the `pyplot` module from the library `matplotlib` and setting an alias of `plt` for it (so that we only have to type `plt.` instead of `matplotlib.pyplot.` each time we want to use it).  Note that `plt` is considered the **_standard alias_** for Matplotlib.\n",
    "\n",
    "Run the cell below to import Matplotlib and use it to create a histogram of our `height` data with 8 different bins. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell without changes\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "# ^^This is a 'magic command' built into jupyter notebooks. We use it so that the visualization displays \n",
    "# in the notebook directly, instead of in a separate window.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll use Matplotlib to create a histogram by passing in our data, as well as the parameter `bins=8`, into the `hist` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:4: SyntaxWarning: 'str' object is not callable; perhaps you missed a comma?\n",
      "<>:4: SyntaxWarning: 'str' object is not callable; perhaps you missed a comma?\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_14464\\1258493750.py:4: SyntaxWarning: 'str' object is not callable; perhaps you missed a comma?\n",
      "  plt.xlable('Height'('inches'))\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_14464\\1258493750.py:4: SyntaxWarning: 'str' object is not callable; perhaps you missed a comma?\n",
      "  plt.xlable('Height'('inches'))\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_14464\\1258493750.py:4: SyntaxWarning: 'str' object is not callable; perhaps you missed a comma?\n",
      "  plt.xlable('Height'('inches'))\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_14464\\1258493750.py:4: SyntaxWarning: 'str' object is not callable; perhaps you missed a comma?\n",
      "  plt.xlable('Height'('inches'))\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_14464\\1258493750.py:4: SyntaxWarning: 'str' object is not callable; perhaps you missed a comma?\n",
      "  plt.xlable('Height'('inches'))\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'matplotlib.pyplot' has no attribute 'xlable'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Run this cell without changes\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# A histogram should display below\u001b[39;00m\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mhist(height, bins\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, edgecolor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblack\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlable(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHeight\u001b[39m\u001b[38;5;124m'\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minches\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mylable(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCount\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHeight Distribution\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'matplotlib.pyplot' has no attribute 'xlable'"
     ]
    }
   ],
   "source": [
    "# Run this cell without changes\n",
    "# A histogram should display below\n",
    "plt.hist(height, bins=8, edgecolor='black')\n",
    "plt.xlable('Height'('inches'))\n",
    "plt.ylable('Count')\n",
    "plt.title('Height Distribution');"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you spot anything unusual above? Some outliers, maybe?\n",
    "\n",
    "## Measures of Central Tendency\n",
    "\n",
    "### Calculating the Mean"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're just beginning to dig into the data stored in `height`. We'll begin by writing a function to calculate the mean of the data.  Recall the formula for calculating mean:\n",
    "\n",
    "$$ \\Large \\bar{x} = \\frac{1}{n} \\sum_{i=1}^{n}x_i $$\n",
    "\n",
    "Using the Python skills you have learned so far, create a function `get_mean()` to perform the following tasks: \n",
    "* Input a list of numbers (like the height list we have above)\n",
    "* Calculate the sum of numbers and length of the list \n",
    "* Calculate mean from above, round off to 2 decimals and return it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "type NoneType doesn't define __round__ method",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m test1 \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m      8\u001b[0m test2 \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28mprint\u001b[39m(get_mean(test1)) \u001b[38;5;66;03m# 3.0\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(get_mean(test2))\n",
      "Cell \u001b[1;32mIn[25], line 5\u001b[0m, in \u001b[0;36mget_mean\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_mean\u001b[39m(data):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# Replace None with appropriate code\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     mean \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mround\u001b[39m(mean,\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: type NoneType doesn't define __round__ method"
     ]
    }
   ],
   "source": [
    "def get_mean(data):\n",
    "    # Replace None with appropriate code\n",
    "    mean = None\n",
    "    \n",
    "    return round(mean,2)\n",
    "\n",
    "test1 = [5, 4, 1, 3, 2]\n",
    "test2 = [4, 2, 3, 1]\n",
    "\n",
    "print(get_mean(test1)) # 3.0\n",
    "print(get_mean(test2)) # 2.5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll test the function by passing in the height list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell without changes\n",
    "mean = get_mean(height)\n",
    "\n",
    "print(\"Sample Mean:\", mean) # Sample Mean: 69.58"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we have our mean length, 69.58, and this confirms our observations from the histogram. But we also have some outliers in our data above and we know outliers affect the mean calculation by pulling the mean value in their direction. So, let's remove these outliers and create a new list to see if our mean shifts or stays. We'll use a threshold of 80 inches, i.e. filter out any values greater than 80. \n",
    " \n",
    "Perform following tasks:\n",
    "\n",
    "* Create a function `filter_height_outliers` that takes a list as an argument\n",
    "* Perform a `for` loop to iteratively check and append values to a new list if the value is less than 80, for every element in the original list\n",
    "* Return the new list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_height_outliers(data):\n",
    "    \n",
    "    filtered_data = []\n",
    "    \n",
    "    # Perform filtering here\n",
    "    \n",
    "    return filtered_data\n",
    "\n",
    "test = [60, 70, 80, 90]\n",
    "filter_height_outliers(test) # [60, 70]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, now we can use `filter_height_outliers()` to filter our `height` list and plot a new histogram to see if things change considerably.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the height list using the above function\n",
    "# Replace None with appropriate code\n",
    "filtered_height = None\n",
    "\n",
    "len(filtered_height) # 4347"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have filtered the outliers out of our data and reduced the size of the dataset from 4785 to 4347, let's recreate our histogram with 8 bins using our filtered data. \n",
    "\n",
    "**_NOTE_**: You do not need to reimport `matplotlib.pyplot as plt` -- once it's been imported, it's stored in memory and can be accessed whenever we like in other cells. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace None with appropriate code\n",
    "# A histogram should display below\n",
    "plt.hist(None, bins=None);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we've filtered our data to remove outliers, we should also recalculate the mean.  Do this now in the cell below, using our `get_mean()` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace None with appropriate code\n",
    "new_mean = None\n",
    "\n",
    "new_mean # 66.85"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does the mean height of our filtered data match up with what we see in our histogram of our filtered data?\n",
    "\n",
    "Note that in some analytical situations we may not be able to exclude the outliers in such a naive manner. So, let's go ahead and calculate other measures of central tendency as well. We'll start by calculating the median value for our original (unfiltered) height data. \n",
    "\n",
    "### Calculating the Median \n",
    "\n",
    "The median is the value directly in the middle of the dataset. In statistical terms, this is the **_Median Quartile_**. If the dataset was sorted from lowest value to highest value, the median is the value that would be larger than the first 50% of the data, and smaller than the second 50%.\n",
    "\n",
    "If the dataset has an odd number of values, then the median is the middle number.\n",
    "If the dataset has an even number of values, then we take the mean of the middle two numbers.\n",
    "\n",
    "In the cell below, write a function that takes in a list of numbers and returns the median value for that dataset. Make sure you first check for even / odd number of data points and perform the computation accordingly. The best approach to calculate the median is as follows:\n",
    "\n",
    "1. Sort the data \n",
    "2. Check if the data has even or odd number of data points \n",
    "3. Calculate the median of the sorted data now that you know if the count is even or odd. \n",
    "\n",
    "Hints:\n",
    "\n",
    " - You can use the modulo operator `%` in Python to check if a value is even or odd -- odd numbers `% 2` (e.g. `5 % 2`) will equal `1`, while even numbers `% 2` (e.g. `4 % 2`) will equal `0`!\n",
    " - You can use integer division `//` to calculate the index -- for even numbers this just means that the result is an integer (e.g. `4 // 2` is `2` rather than `2.0`), while for odd numbers this means that the remainder is cut off (e.g. `7 // 2` is `3`, not `3.5`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_median(data):\n",
    "    # Replace None with appropriate code\n",
    "    data_sorted = None\n",
    "    \n",
    "    # Your code here\n",
    "    # Check for even/odd and perform calculations accordingly - use if-else \n",
    "\n",
    "test1 = [5, 4, 1, 3, 2]\n",
    "test2 = [4, 2, 3, 1]\n",
    "\n",
    "print(get_median(test1)) # 3\n",
    "print(get_median(test2)) # 2.5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, now we can pass in our original `height` list to this function to check the median. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace None with appropriate code\n",
    "median = None\n",
    "\n",
    "median # 67"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we have 67, which is much closer to the filtered list mean (66.85) than the mean we calculated with actual list (69.58). So, median in this case seems to be a much better indicator of the central tendency found in the dataset. This makes sense because we've already learned that medians are less sensitive to outliers than mean values are! \n",
    "\n",
    "Next, we'll calculate the mode. This could give us better insight into the typical values in the dataset based on how frequent a value is.  \n",
    "\n",
    "### Calculating the Mode\n",
    "\n",
    "The mode is the value that shows up the most in a dataset. A dataset can have 0 or more modes. If no value shows up more than once, the dataset is considered to have no mode value. If two numbers show up the same number of times, that dataset is considered bimodal. Datasets where multiple values all show up the same number of times are considered multimodal.\n",
    "\n",
    "In the cell below, write a function that takes in a list of numbers and returns another list containing the mode value(s). In the case of only one mode, the list would have a single element. \n",
    "\n",
    "**_Hint_**: Building a **_frequency distribution_** table using dictionaries is probably the easiest way to approach this problem. Use each unique element from the height list as a key, and the frequency of this element as the value and build a dictionary. You can then simply identify the keys (heights) with maximum values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Throughout this cell, replace None with appropriate code\n",
    "\n",
    "def get_mode(data):\n",
    "\n",
    "    # Create and populate frequency distribution\n",
    "    frequency_dict = {}\n",
    "    \n",
    "    for height in data:\n",
    "        # If an element is not in the dict, add it to the dict with value 1\n",
    "        # If an element is already in the dict, +1 the value in place\n",
    "        None\n",
    "    \n",
    "    # Find the frequency of the mode(s) by finding the largest\n",
    "    # value in frequency_dict\n",
    "    highest_freq = None\n",
    "    \n",
    "    # Create a list for mode values\n",
    "    modes = []\n",
    "    \n",
    "    # From the dictionary, add element(s) to the modes list with max frequency\n",
    "    for height, frequency in frequency_dict.items():\n",
    "        None\n",
    "\n",
    "    # Return the mode list \n",
    "    return modes\n",
    "\n",
    "test1 = [1, 2, 3, 5, 5, 4]\n",
    "test2 = [1, 1, 1, 2, 3, 4, 5, 5, 5]\n",
    "\n",
    "print(get_mode(test1)) # [5]\n",
    "print(get_mode(test2)) # [1, 5]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's done. Now you can use the above function to calculate the mode of the original `height` list to compare it with our mean and median values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Replace None with appropriate code\n",
    "mode = None\n",
    "\n",
    "mode # [64]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the mode value is much lower than our mean and median calculated earlier. What do you make of this? The answer to that could be subjective and depends on the problem. i.e. if your problem is to identify sizes for garments that would sell the most, you cannot disregard mode. However, if you want to get an idea about the general or typical height of individuals, you can probably still do that with the median and the average. \n",
    "\n",
    "To get an even clearer picture, we know we need to see how much the values deviate from the central values we have identified. We have seen variance and standard deviation before as measures of such dispersion. Let's have a go at these to strengthen our understanding of this data. \n",
    "\n",
    "## Measures of Dispersion\n",
    "\n",
    "### Calculating the Variance\n",
    "\n",
    "The formula for variance is: \n",
    "\n",
    "$$ \\Large s^2 = \\frac{1}{n - 1} \\sum_{i=1}^{n}(x_i - \\bar{x})^2 $$\n",
    "\n",
    "Note that this formula is for the **sample** variance. The formula is slightly different than the formula for calculating population variance. Read more about the difference [here](https://www.macroption.com/population-sample-variance-standard-deviation/). In the cell below, write a function that takes a list of numbers as input and returns the variance (rounded to two decimal places) of the sample as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_mean' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m test1 \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m4\u001b[39m]\n\u001b[0;32m     21\u001b[0m test2 \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m5\u001b[39m]\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28mprint\u001b[39m(get_variance(test1)) \u001b[38;5;66;03m# 2.67\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(get_mean(test1)) \u001b[38;5;66;03m# 3.33\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(get_variance(test2))\n",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m, in \u001b[0;36mget_variance\u001b[1;34m(sample)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_variance\u001b[39m(sample):\n\u001b[0;32m      4\u001b[0m \n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# First, calculate the sample mean using get_mean()\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m     sample_mean \u001b[38;5;241m=\u001b[39m get_mean(sample)\n\u001b[0;32m      8\u001b[0m     sum_of_squares \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m height \u001b[38;5;129;01min\u001b[39;00m sample:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_mean' is not defined"
     ]
    }
   ],
   "source": [
    "# Replace None with appropriate code\n",
    "\n",
    "def get_variance(sample):\n",
    "\n",
    "    # First, calculate the sample mean using get_mean()\n",
    "    sample_mean = get_mean(sample)\n",
    "    \n",
    "    sum_of_squares = None\n",
    "    for height in sample:\n",
    "        sum_of_squares += (height - sample_mean)**2\n",
    "        # Now, calculate the sum of squares by subtracting the sample mean\n",
    "        # from each height, squaring the result, and adding it to the total\n",
    "        \n",
    "        \n",
    "    # Divide the sum of squares by the number of items in the sample -1 to calculate variance \n",
    "    variance = sum_of_squares/ (len(sample)-1)\n",
    "    \n",
    "    return round(variance, 2)\n",
    "\n",
    "test1 = [1, 2, 3, 5, 5, 4]\n",
    "test2 = [1, 1, 1, 2, 3, 4, 5, 5, 5]\n",
    "print(get_variance(test1)) # 2.67\n",
    "print(get_mean(test1)) # 3.33\n",
    "print(get_variance(test2)) # 3.25"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can test the variance of our list `height` with our new `get_variance()` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace None with appropriate code\n",
    "variance = None\n",
    "\n",
    "variance # 87.74"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this value, as we learned earlier, tells us a bit about the deviation but not in the units of underlying data. This is because it squares the values of deviations. Standard deviation, however, can deal with this issue as it takes the square roots of differences. So that would probably be a bit more revealing. \n",
    "\n",
    "## Calculating the Standard Deviation\n",
    "\n",
    "In the cell below, write a function that takes a list of numbers as input and returns the standard deviation of that sample as output.\n",
    "\n",
    "Recall that the formula for Standard Deviation is:\n",
    "\n",
    "$$ \\Large s = \\sqrt{\\frac{1}{n-1} \\sum_{i=1}^{n}(x_i - \\bar{x})^2} $$\n",
    "\n",
    "To find the square root of a value in Python, you have two options (**either** approach will work):\n",
    "\n",
    "One option is the `sqrt()` function from `math` library:\n",
    "\n",
    "```python\n",
    "from math import sqrt\n",
    "sqrt(100) # 10.0\n",
    "```\n",
    "\n",
    "Alternatively, another approach would be to raise that number to the power of `0.5`:\n",
    "\n",
    "```python\n",
    "100**0.5 # 10.0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace None with appropriate code\n",
    "from math import sqrt\n",
    "\n",
    "def get_stddev(sample):\n",
    "    \n",
    "    stddev = None\n",
    "    \n",
    "    return round(stddev, 2)\n",
    "\n",
    "test = [120,112,131,211,312,90]\n",
    "\n",
    "get_stddev(test) # 84.03"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we can finally calculate the standard deviation for our `height` list and inspect the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace None with appropriate code\n",
    "standard_deviation = None\n",
    "\n",
    "standard_deviation # 9.37"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So 9.37 inches is the amount of deviation present in our dataset. As we are still including outlier values, this might be slightly affected but these results are now much more reliable. \n",
    "\n",
    "Finally, we will build a boxplot for height data and see if it agrees with our understanding for this data that we have developed up to this point. Use the `matplotlib`'s `boxplot()` function with height data and comment on the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace None with appropriate code\n",
    "# A boxplot should display below\n",
    "plt.boxplot(None);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplifying the Process with NumPy\n",
    "\n",
    "We hope writing these functions was a useful experience in terms of deepening your understanding of these statistical measures as well as sharpening your Python skills. However in reality there is almost never a need to write these kinds of functions \"by hand\", since libraries like NumPy and SciPy can typically handle them for us in a single line.\n",
    "\n",
    "Below is a demonstration of the same calculations performed above, written using Python libraries side-by-side with the results of the functions you've just written:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell without changes\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "print(\"Mean:\")\n",
    "print(mean, \"(our version)\")\n",
    "print(round(np.mean(height), 2), \"(NumPy version)\")\n",
    "print()\n",
    "print(\"Median:\")\n",
    "print(median, \"(our version)\")\n",
    "print(np.median(height), \"(NumPy version)\")\n",
    "print()\n",
    "print(\"Mode:\")\n",
    "print(mode, \"(our version)\")\n",
    "print(stats.mode(height, keepdims=True).mode, \"(SciPy version)\")\n",
    "print()\n",
    "print(\"Variance:\")\n",
    "print(variance, \"(our version)\")\n",
    "print(round(np.var(height, ddof=1), 2), \"(NumPy version)\")\n",
    "print()\n",
    "print(\"Standard Deviation:\")\n",
    "print(standard_deviation, \"(our version)\")\n",
    "print(round(np.std(height, ddof=1), 2), \"(NumPy version)\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary \n",
    "\n",
    "In this lab, we performed a basic, yet detailed, statistical analysis around measuring the tendencies of center and spread for a given dataset. We looked at building a number of functions to calculate different measures and also used some statistical visualizations to strengthen our intuitions around the dataset. We shall see how we can simplify this process as we study `numpy` and `pandas` libraries to ease out the programming load while calculating basic statistics. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
